---
title: "Machine Learning Project"
output: html_document
---




This report aims to study the data generated by wearable gadgets to try to predict the excercise type performed by trainee 

```{r, echo=FALSE, cache=TRUE}
library('parallel')
library('RCurl')
library('caret');
library('kernlab');
```


First the Data is read from the remote URL 

```{r, echo=FALSE, cache=TRUE}
training_file<-'pml-training.csv'
test_file<-'pml-testing.csv'

files_url<-'https://d396qusza40orc.cloudfront.net/predmachlearn/'
training_url<-paste(files_url,training_file,sep="")
testing_url<-paste(files_url,test_file,sep="")
print(training_url)
print(testing_url)

if(!exists('xURL_training')) {
  xURL_training<-getURL(training_url,ssl.verifypeer=FALSE)  
}

if(!exists('xURL_testing')) {
  xURL_testing<-getURL(testing_url,ssl.verifypeer=FALSE)
}

if (!exists('maindf')) {
  maindf<-read.csv(textConnection(xURL_training))
}

if (!exists('testdf')) {
  testdf<-read.csv(textConnection(xURL_testing))
}
traindf<-maindf
```
Now The data fields that are not required for the analysis are to be removed
First we remove the ID field 
```{r, echo=FALSE, cache=TRUE}

#remove ID
traindf<-traindf[,-1]
set.seed(1234)
```
The existing records are divided into two partitions, one for training and another one for testing 
```{r, echo=FALSE, cache=TRUE}
inTrain<-createDataPartition(y=traindf$classe,p=0.2,list=FALSE)

#summary(traindf)
#summary(testdf)
```
The fields with too many missing values are excluded , here we assume that fields of 40% or more missing data should be removed from our analysis 
```{r, echo=FALSE, cache=TRUE}
na_count = sapply(traindf, function(x) {sum(is.na(x))})
percent<-0.4
na_cols<- names(na_count[na_count>percent*nrow(traindf)])
traindf <- traindf[, !names(traindf) %in% na_cols]

```
Only the fields related to the movement and the username and the class are taken into consideration for our analysis , so the rest of the fields are dropped 
```{r, echo=FALSE, cache=TRUE}
names<-colnames(traindf)
mycols<-grep('arm',names)
mycols<-c(mycols,grep('forearm',names))
mycols<-c(mycols,grep('belt',names))
mycols<-c(mycols,grep('user_name',names))
mycols<-c(mycols,grep('class',names))
mycols<-sort(unique(mycols))



traindf<-traindf[,mycols]

training<-traindf[inTrain,]
testing<-traindf[-inTrain,]

```
Make sure only numeric fields are kept in the data frame
```{r, echo=FALSE}

numeric_columns<-sapply(training,is.numeric)

traindf<-training[,numeric_columns]
testdf<-testing[,numeric_columns]
# if(!exists('nearzerovariancecols')) {
#   nearzerovariancecols<-nearZeroVar(traindf)
#   
# }

traindf2<-traindf
testdf2<-testdf


traindf2$classe<-training$classe
testdf2$classe<-testing$classe
```
Repeated Cross Validation is used, with folds set to 8 and repeats set to 3
```{r, echo=FALSE, cache=TRUE}
control <- trainControl(method="repeatedcv", number=10, repeats=3)



```
```{r, echo=FALSE}
library('caret');
  modfit1<-train(classe~.,data=traindf2,preProcess=c("pca","knnImpute"),trControl=control)
  
```

```{r, echo=FALSE}
predictions1<-predict(modfit1,testdf2,na.action=na.pass)
```
```{r, echo=FALSE}
cm1<-confusionMatrix(predictions1,testdf2$classe)
```


```{r, echo=FALSE}
cm1
```